#Import numpy to work with tweets as a DataFrame
import numpy as np 
import pandas as pd 

#Import matplotlib to plot graphs and wordcloud
import matplotlib.pyplot as plt 
import re
import time

#Import NLTK for sentiment analysis
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import *
from nltk.classify import NaiveBayesClassifier
from wordcloud import WordCloud

#Import Tweepy to connect and scrape tweets from Twitter's API
import tweepy
from tweepy import OAuthHandler 

# for showing all the plots inline
%matplotlib inline

##Getting User information from Tweets
#Setting up the code to pull and covert tweets to a CSV file
tweets = []

def text_query_to_csv(text_query,count):
    try:
        # Creation of query method using parameters
        tweets = tweepy.Cursor(api.search_tweets,q=text_query,tweet_mode='extended',lang='en',result_type='mixed').items(count) 
       
        # Pulling information from tweets iterable object
        tweets_list = [[tweet.id, tweet.created_at, tweet.full_text, tweet.user.screen_name, tweet.user.id,
                       tweet.user.location, tweet.user.description, tweet.user.followers_count] for tweet in tweets]
        print("Number of tweets extracted: {}.\n".format(len(tweets_list)))
        
        # Creation of dataframe from tweets list
        tweets_df = pd.DataFrame(tweets_list,columns=['Tweet Id', 'Tweet Datetime', 'Tweet Text', 'Twitter Handle',
                                                     'Twitter User ID', 'Twitter User Location', 'Twitter User Description',
                                                     'User Followers Count'])
        

        # Converting dataframe to CSV 
        tweets_df.to_csv('{}-tweets.csv'.format(text_query), sep=',', index = False)

    except BaseException as e:
        print('failed on_status,',str(e))
        time.sleep(3)
        

##Here is where we input the query, which takes a string input and count the number of tweets to pull
# Input search query to scrape tweets and name csv file
# Max recent tweets pulls x amount of most recent tweets from that user
text_query = 'Ukraine War'
count = 20000

# Calling function to query X amount of relevant tweets and create a CSV file
text_query_to_csv(text_query, count)

#Reimport the CSV into a pandas DataFrame
df = pd.read_csv('20kUkraine war-tweets.csv')
df.head()

##Tweet Cleaning using NLTK and Regex, removing any http links, hashtags(but keeping the text) and @ signs
#Import the necessary libraries to analyse the text
words = set(nltk.corpus.words.words())

#Clean Tweets using Regex
def cleaner(tweet):
    tweet = re.sub("@[A-Za-z0-9]+","",tweet) #Remove @ sign
    tweet = re.sub(r"(?:\@|http?\://|https?\://|www)\S+", "", tweet) #Remove http links
    tweet = " ".join(tweet.split())
    tweet = tweet.replace("#", "").replace("_", " ") #Remove hashtag sign but keep the text
    tweet = " ".join(w for w in nltk.wordpunct_tokenize(tweet)
                     if w.lower() in words or not w.isalpha())
    return tweet
    
df['Clean Tweet'] = df['Tweet Text'].apply(cleaner)

#Remove tweets with empty text
df = df[df['Clean Tweet']!='']

#Drop duplicate rows
df.drop_duplicates(subset=['Clean Tweet'], keep=False)

#Reset index
df = df.reset_index(drop=True)
df.head()


